#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Jul 20 14:55:22 2021

@author: gz_fan
"""
import torch
from mlcpt.ml import MLP
from mlcpt.common.seed import fix_seed

# X_train = torch.tensor([[
#         2.872340e+00,  7.989645e-01,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           9.974638e-01,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  1.005319e+00],
#         [ 1.153353e+00,  8.532913e-03,  7.202091e-01,  2.013296e-01,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           4.133862e-02,  8.302436e-02,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -2.520732e-01],
#         [ 1.179889e+00,  4.171474e-03,  7.346196e-01,  2.352155e-01,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           4.310735e-02,  8.350062e-02,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -2.571169e-01],
#         [ 9.650784e-01,  8.992945e-04,  6.874923e-01,  1.384595e-01,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           2.423285e-02,  4.341516e-02,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -2.406223e-01],
#         [ 1.250956e+00,  1.006067e-02,  7.300188e-01,  2.239600e-01,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           5.225557e-02,  1.022796e-01,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -2.555066e-01],
#         [ 2.857078e+00,  7.579073e-01,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           9.622617e-01,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  9.999773e-01],
#         [ 1.165472e+00,  8.168658e-03,  7.049136e-01,  1.696184e-01,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           4.134076e-02,  8.300668e-02,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -2.467197e-01],
#         [ 1.008174e+00,  9.942334e-04,  7.094816e-01,  1.786465e-01,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           2.710173e-02,  5.101391e-02,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -2.483186e-01],
#         [ 1.194606e+00,  8.617750e-03,  7.315000e-01,  2.275384e-01,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           4.459884e-02,  9.386816e-02,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -2.560250e-01],
#         [ 1.079742e+00,  1.776863e-03,  7.111830e-01,  1.821039e-01,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           3.285345e-02,  6.307872e-02,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -2.489140e-01],
#         [ 2.328479e+00,  1.073520e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           8.197829e-01,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  1.955923e+00],
#         [ 9.022400e-01,  1.256440e-02,  0.000000e+00,  0.000000e+00,
#           7.864344e-01,  3.916284e-01,  0.000000e+00,  0.000000e+00,
#           2.399121e-02,  0.000000e+00,  0.000000e+00,  6.525309e-02,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -6.606049e-01],
#         [ 8.422983e-01,  5.012412e-03,  0.000000e+00,  0.000000e+00,
#           7.834665e-01,  3.811916e-01,  0.000000e+00,  0.000000e+00,
#           1.947030e-02,  0.000000e+00,  0.000000e+00,  4.511936e-02,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -6.581118e-01],
#         [ 9.666848e-01,  1.543395e-02,  0.000000e+00,  0.000000e+00,
#           7.585785e-01,  3.007004e-01,  0.000000e+00,  0.000000e+00,
#           3.065627e-02,  0.000000e+00,  0.000000e+00,  7.564260e-02,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -6.372060e-01],
#         [ 2.306746e+00,  1.001167e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           7.536676e-01,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  1.937667e+00],
#         [ 9.999849e-01,  1.831383e-02,  0.000000e+00,  0.000000e+00,
#           7.673604e-01,  3.276510e-01,  0.000000e+00,  0.000000e+00,
#           3.207750e-02,  0.000000e+00,  0.000000e+00,  9.196360e-02,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -6.445827e-01],
#         [ 1.163922e+00,  1.135816e-01,  0.000000e+00,  0.000000e+00,
#           7.568955e-01,  2.957171e-01,  0.000000e+00,  0.000000e+00,
#           6.275150e-02,  0.000000e+00,  0.000000e+00,  1.536918e-01,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -6.357922e-01],
#         [ 1.164910e+00,  1.137379e-01,  0.000000e+00,  0.000000e+00,
#           7.824907e-01,  3.777985e-01,  0.000000e+00,  0.000000e+00,
#           6.303171e-02,  0.000000e+00,  0.000000e+00,  1.726507e-01,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -6.572922e-01],
#         [ 1.645394e+00,  1.072366e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           4.046095e-01,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  2.040288e+00],
#         [ 5.641552e-01,  2.599422e-02,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  7.970124e-01,  4.302154e-01,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  4.163283e-02,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -9.882953e-01],
#         [ 5.641552e-01,  2.599422e-02,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  8.483815e-01,  6.421511e-01,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  5.868424e-02,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -1.051993e+00],
#         [ 1.599270e+00,  8.867327e-01,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           2.868538e-01,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  1.983094e+00],
#         [ 6.839263e-01,  1.326907e-01,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  7.805592e-01,  3.711384e-01,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  1.082563e-01,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -9.678935e-01],
#         [ 6.839263e-01,  1.326907e-01,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  8.187104e-01,  5.155943e-01,
#           0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,
#           0.000000e+00,  0.000000e+00,  1.408395e-01,  0.000000e+00,
#           0.000000e+00,  0.000000e+00, -1.015201e+00]])
# y_train = torch.tensor([ 0.304517, -0.081390, -0.075134, -0.081857, -0.066137,  0.294891,
#         -0.060898, -0.083902, -0.078906, -0.071185,  0.567379, -0.200155,
#         -0.204977, -0.162247,  0.527924, -0.171699, -0.170899, -0.185326,
#          0.606249, -0.293805, -0.312445,  0.590561, -0.285294, -0.305266])
# X_test = X_train.clone()

@fix_seed
def test_mlp():
    X_train = torch.randn(50, 10)
    X_test = torch.randn(20, 10)
    y_train = torch.randn(50, 1)
    mlp = MLP(X_train, y_train, n_hidden_layer=[10, 5], max_iter=20, initialization='xavier')
    pred = mlp(X_test)
    print('result', pred)

    from sklearn.neural_network import MLPRegressor
    clf = MLPRegressor(solver='lbfgs', alpha=1e-5, activation='relu',
                     hidden_layer_sizes=(10, 10), random_state=3, max_iter=3)
    clf.fit(X_train, y_train)
    print(clf.predict(X_test))

test_mlp()
